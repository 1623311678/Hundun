import { Meta } from "@storybook/addon-docs";
import mvcPng from "../assets/node-mvc.png";
import mvcFlowPng from "../assets/mvc-flow.png";

<Meta title="Hundun/现代高可用软件设计/基于阿里云的k8s自动扩容架构" />

# 基于阿里云的k8s自动扩容架构


https://kubernetes.io/zh-cn/docs/home/supported-doc-versions/

## Node.js服务在K8s上的部署与自动扩容全流程（以阿里云主机为例）

### 1. 环境准备
- 一台或多台阿里云ECS主机，推荐CentOS/Ubuntu，已开放必要端口（如6443、30000-32767等）
- 安装Docker、Kubernetes（可用kubeadm/k3s/ACK等）、kubectl
- 可选：使用阿里云ACK托管K8s，省去集群搭建

#### 关键命令
```bash
# 安装Docker
curl -fsSL https://get.docker.com | bash
# 安装kubectl
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
chmod +x ./kubectl && mv ./kubectl /usr/local/bin/
# 安装kubeadm/kubelet（如自建K8s）
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet
```

---

### 2. 构建Node.js服务镜像
- 编写Dockerfile
```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install --production
COPY . .
EXPOSE 3000
CMD ["node", "app.js"]
```
- 构建并推送镜像（以阿里云镜像仓库为例）
```bash
# 登录阿里云镜像仓库
docker login --username=xxx registry.cn-hangzhou.aliyuncs.com
# 构建镜像
docker build -t registry.cn-hangzhou.aliyuncs.com/yourrepo/node-demo:latest .
# 推送镜像
docker push registry.cn-hangzhou.aliyuncs.com/yourrepo/node-demo:latest
```

---

### 3. 编写K8s部署YAML
#### deployment.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: node-demo
  template:
    metadata:
      labels:
        app: node-demo
    spec:
      containers:
      - name: node-demo
        image: registry.cn-hangzhou.aliyuncs.com/yourrepo/node-demo:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /healthz
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        imagePullSecrets:
      # volumes:
      # - name: config
      #   configMap:
      #     name: myapp-config
      # - name: aliyun-registry
```
#### service.yaml
```yaml
apiVersion: v1
kind: Service
metadata:
  name: node-demo-svc
spec:
  type: NodePort
  selector:
    app: node-demo
  ports:
  - port: 80
    targetPort: 3000
    nodePort: 30080
```

---

### 4. 部署到K8s
```bash
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
kubectl get pods,svc
```
- 通过`ECS公网IP:30080`访问服务

---

### 5. 配置自动扩容（HPA）
- 开启K8s Metrics Server（用于采集Pod资源指标）
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```
- 创建HPA自动扩容配置
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: node-demo-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: node-demo
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
```
```bash
kubectl apply -f hpa.yaml
kubectl get hpa
```
- 当CPU利用率超过60%，Pod会自动扩容，低于阈值自动缩容

---

### 6. 进阶与最佳实践
- 配置Ingress+SLB实现公网高可用访问
- 配置ConfigMap/Secret管理环境变量与敏感信息
- 日志采集接入SLS，监控接入ARMS
- 结合CI/CD自动化发布

## deployment.yaml 配置详解

Kubernetes Deployment 用于声明式管理无状态服务的副本、升级、回滚等。以下是典型 Node.js 服务 deployment.yaml 的详细字段说明：

```yaml
apiVersion: apps/v1           # API版本，生产建议用apps/v1
kind: Deployment              # 资源类型
metadata:
  name: node-demo             # Deployment名称
  labels:
    app: node-demo            # 标签，便于选择器和管理
spec:
  replicas: 2                 # 副本数，Pod数量，结合HPA可自动扩缩容
  selector:
    matchLabels:
      app: node-demo          # 选择器，匹配Pod标签
  template:
    metadata:
      labels:
        app: node-demo        # Pod标签，需与selector一致
    spec:
      containers:
      - name: node-demo       # 容器名称
        image: registry.cn-hangzhou.aliyuncs.com/yourrepo/node-demo:latest # 镜像地址
        ports:
        - containerPort: 3000 # 容器对外暴露端口
        env:                  # 环境变量（如有）
        - name: NODE_ENV
          value: "production"
        resources:            # 资源请求与限制，便于调度与弹性扩容
          requests:
            cpu: 100m         # 最小CPU
            memory: 128Mi     # 最小内存
          limits:
            cpu: 500m         # 最大CPU
            memory: 512Mi     # 最大内存
        livenessProbe:        # 存活探针，自动重启异常Pod
          httpGet:
            path: /healthz
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:       # 就绪探针，流量只转发给健康Pod
          httpGet:
            path: /healthz
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:         # 挂载卷（如有）
        # - name: config
        #   mountPath: /app/config
      # volumes:              # 卷定义（如有）
      # - name: config
      #   configMap:
      #     name: myapp-config
      imagePullSecrets:       # 私有仓库拉取镜像凭证（如有）
      # - name: aliyun-registry
```

### 主要字段说明
- **replicas**：Pod副本数，结合HPA可弹性伸缩
- **selector/template.metadata.labels**：Pod选择与分组依据，需一致
- **containers.image**：镜像地址，建议用CI/CD自动推送
- **resources**：合理设置可防止资源争抢，利于自动扩容
- **livenessProbe/readinessProbe**：健康检查，提升高可用性
- **env/volumeMounts/volumes**：环境变量、配置挂载，便于多环境部署
- **imagePullSecrets**：私有镜像仓库需配置

### 最佳实践
- 配置健康探针，避免流量打到未就绪/异常Pod
- 合理设置资源请求/限制，防止资源耗尽或浪费
- 结合ConfigMap/Secret管理配置与敏感信息
- 镜像版本号建议用CI自动生成，避免latest带来的不可控
- 结合HPA实现自动弹性扩缩容

> deployment.yaml 是K8s无状态服务的核心声明文件，建议结合实际业务需求灵活配置。

> 以上流程适用于阿里云ECS自建K8s或ACK托管K8s，Node.js服务可实现弹性伸缩与高可用部署。遇到问题可参考[官方文档](https://kubernetes.io/zh-cn/docs/home/supported-doc-versions/)或阿里云ACK文档。

## service.yaml 配置详解

Kubernetes Service 用于为一组Pod提供稳定的网络访问入口，实现服务发现与负载均衡。以下是典型 Node.js 服务 service.yaml 的详细字段说明：

```yaml
apiVersion: v1                # API版本
kind: Service                 # 资源类型
metadata:
  name: node-demo-svc         # Service名称
  labels:
    app: node-demo            # 标签，便于管理
spec:
  type: NodePort              # Service类型（ClusterIP/NodePort/LoadBalancer）
  selector:
    app: node-demo            # 选择器，关联Pod标签
  ports:
  - port: 80                  # Service暴露端口（集群内访问）
    targetPort: 3000          # Pod容器端口
    nodePort: 30080           # 节点端口（仅NodePort/LoadBalancer类型）
```

### 主要字段说明
- **type**：
  - `ClusterIP`（默认）：仅集群内可访问，适合服务间调用
  - `NodePort`：集群每个节点开放端口，外部可通过`节点IP:nodePort`访问
  - `LoadBalancer`：云平台自动分配公网负载均衡IP（如阿里云SLB），推荐生产环境
- **selector**：根据标签选择关联的Pod，需与Deployment一致
- **ports.port**：Service对外暴露的端口（如80）
- **ports.targetPort**：Pod容器实际监听端口（如3000）
- **ports.nodePort**：节点端口，范围30000-32767，外部访问用

### 最佳实践
- 生产环境推荐用`LoadBalancer`类型，结合云SLB实现高可用公网访问
- 内部服务间调用用`ClusterIP`，无需暴露外网
- 端口命名规范，便于多端口服务管理
- selector与Deployment保持一致，确保流量正确路由
- 结合Ingress实现基于域名的七层路由

### 进阶用法
- 支持多端口、多协议（TCP/UDP）
- 可结合ExternalName、Headless Service实现服务发现/直连

> service.yaml 是K8s服务暴露与发现的核心声明文件，建议结合实际访问需求灵活配置。

## HPA（HorizontalPodAutoscaler）自动扩容配置详解

Kubernetes HPA（水平自动扩缩容）可根据Pod的CPU、内存或自定义指标，自动调整Deployment/StatefulSet的副本数，实现弹性伸缩。

### 典型HPA配置示例
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: node-demo-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: node-demo
  minReplicas: 2           # 最小副本数，低于此不会缩容
  maxReplicas: 10          # 最大副本数，超过此不会再扩容
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60  # 目标CPU利用率（百分比）
```

### 主要字段说明
- **minReplicas**：最小Pod副本数，保证基础容量（如2）
- **maxReplicas**：最大Pod副本数，扩容上限（如10），防止资源耗尽或费用失控
- **metrics**：扩缩容依据，可选CPU、内存、或自定义指标（如QPS、队列长度等）
- **averageUtilization**：目标利用率，超出则扩容，低于则缩容
- **scaleTargetRef**：关联的Deployment/StatefulSet等

### 扩容原理
- K8s Metrics Server采集Pod资源指标，HPA控制器定期（默认30秒）评估是否需要扩/缩容
- 若平均CPU利用率>目标值，自动增加Pod副本，直至maxReplicas
- 若低于目标值，自动减少Pod副本，直至minReplicas

### 最佳实践
- maxReplicas建议结合节点资源、业务峰值合理设置，防止过度扩容导致节点资源耗尽
- minReplicas建议≥2，保证高可用
- 生产环境建议监控HPA行为，防止频繁扩缩容（可调节cooldown参数）
- 可结合多指标（如CPU+自定义QPS）实现更智能的弹性
- 业务需无状态，Pod可随时扩缩

### 常见问题
- HPA依赖Metrics Server，需提前部署并保证可用
- 若Pod资源requests/limits未设置，HPA无法正确评估
- maxReplicas受限于集群节点总资源，需结合节点数规划

> HPA是K8s弹性伸缩的核心机制，合理配置minReplicas/maxReplicas和指标阈值，可实现高可用、高性价比的自动扩容。

## 容器副本数与节点资源关系总结

### 1. replicas 含义
- `replicas` 表示期望同时运行的 Pod（容器组）数量，K8s 会自动调度这些 Pod 到集群内的节点（虚拟机）上。
- 每个 Pod 通常运行一个主业务容器（如 Node.js），也可包含 sidecar。

### 2. 一台虚拟机能运行多少容器？
- 取决于节点（虚拟机）的 CPU、内存等资源，以及每个 Pod 的 requests/limits 配置。
- **计算公式**：
  - 最大容器数 = min(节点总CPU / Pod单个CPU requests, 节点总内存 / Pod单个内存 requests)
- **举例**：
  - 节点资源：4核8G
  - Pod requests: 0.5核1G
  - 最大容器数 = min(4/0.5=8, 8/1=8) ⇒ 理论最多8个Pod
  - 实际部署建议预留系统和K8s组件资源，实际可用6-7个Pod
- 若只有一台虚拟机，所有Pod都调度在这台机器上，**不建议生产只用一台**，否则高可用性无法保障。

### 3. 阿里云K8s（ACK）是什么？
- **ACK（Alibaba Cloud Container Service for Kubernetes）** 是阿里云提供的托管Kubernetes服务。
- **优势**：
  - 一键创建高可用K8s集群，免去手动搭建和运维
  - 支持弹性伸缩、自动修复、云原生生态集成（SLB、RDS、OSS、ARMS等）
  - 与阿里云安全、监控、网络、存储等产品深度集成
  - 适合生产环境、企业级高可用、弹性、自动化场景
- **使用方式**：可在阿里云控制台直接创建ACK集群，支持ECS虚拟机、弹性裸金属、Serverless等多种节点类型

### 4. 总结建议
- `replicas` 控制Pod总数，K8s自动分布到节点上
- 单节点可容纳Pod数=节点资源/Pod requests，实际部署需预留系统资源
- 生产建议多节点+合理资源配置+HPA弹性扩容，保障高可用与资源利用率
- 推荐使用阿里云ACK托管K8s，省心高可用，易于与云产品集成

> 合理设置replicas和资源requests/limits，结合ACK托管K8s，可实现高可用、弹性、自动化的现代云原生架构。